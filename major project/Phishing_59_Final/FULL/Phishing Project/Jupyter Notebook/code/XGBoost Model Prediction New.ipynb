{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e6191e0-6f9b-4dea-bf7c-43077f9a5589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.84\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a new website URL:  https://briefingday.com/n/20200618/m#commentform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Result:\n",
      "⚠️ Warning: This URL might be a PHISHING site!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your datasets\n",
    "train = pd.read_csv(\"../data/train_encoded.csv\")\n",
    "test = pd.read_csv(\"../data/test_encoded.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train.drop(columns=['Label'])\n",
    "y_train = train['Label']\n",
    "\n",
    "X_test = test.drop(columns=['Label'])\n",
    "y_test = test['Label']\n",
    "\n",
    "# Train the model\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate accuracy\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# ---- New Link Prediction ---- #\n",
    "\n",
    "# Function to manually extract features from a new URL\n",
    "def extract_features(url):\n",
    "    features = {}\n",
    "    features['url_length'] = len(url)\n",
    "    features['num_dots'] = url.count('.')\n",
    "    features['num_hyphens'] = url.count('-')\n",
    "    features['has_at'] = int('@' in url)\n",
    "    features['has_https'] = int('https' in url.lower())\n",
    "    features['has_ip'] = int(any(char.isdigit() for char in url.split('/')[2])) if '://' in url else 0\n",
    "    features['count_suspicious_words'] = sum(word in url.lower() for word in ['secure', 'account', 'update', 'login', 'verify'])\n",
    "    \n",
    "    return pd.DataFrame([features])\n",
    "\n",
    "# Take a new URL input\n",
    "new_url = input(\"Enter a new website URL: \")\n",
    "\n",
    "# Extract features\n",
    "new_url_features = extract_features(new_url)\n",
    "\n",
    "# Ensure same columns as training data (fill missing ones with 0)\n",
    "missing_cols = set(X_train.columns) - set(new_url_features.columns)\n",
    "for col in missing_cols:\n",
    "    new_url_features[col] = 0\n",
    "\n",
    "new_url_features = new_url_features[X_train.columns]  # Reorder columns\n",
    "\n",
    "# Predict\n",
    "new_prediction = xgb_model.predict(new_url_features)\n",
    "\n",
    "# Display result\n",
    "print(\"\\nPrediction Result:\")\n",
    "if new_prediction[0] == 1:\n",
    "    print(\"⚠️ Warning: This URL might be a PHISHING site!\")\n",
    "else:\n",
    "    print(\"✅ This URL seems SAFE.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c38a8d1-1392-469c-8eb0-0a417e1482c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\divesh\\anaconda3\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [12:57:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the web address (URL) to check: 3souls.us/123H/b4rky/b4rky/P1.html?rAtm1d=;8dcd50af3804821120990f23500e12418dcd50af380482\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['col_0', 'col_1', 'col_2', 'col_3', 'col_4', 'url_length', 'num_dots', 'num_hyphens', 'has_at', 'has_https', 'has_ip', 'count_suspicious_words'] ['url_length', 'num_dots', 'num_hyphens', 'has_at', 'has_https', 'has_ip', 'count_suspicious_words']\nexpected col_4, col_2, col_0, col_3, col_1 in input data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m input_df \u001b[38;5;241m=\u001b[39m input_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# 7. Make a prediction\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mxg_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_df\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# 8. Output the result\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1553\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1545\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1546\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1550\u001b[0m     iteration_range: Optional[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1551\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m-> 1553\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[0;32m   1561\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1168\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1168\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m   1177\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py:2418\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2416\u001b[0m     data, fns, _ \u001b[38;5;241m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[0;32m   2417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[1;32m-> 2418\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data) \u001b[38;5;129;01mor\u001b[39;00m _is_tuple(data):\n\u001b[0;32m   2420\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py:2970\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[1;34m(self, feature_names)\u001b[0m\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m my_missing:\n\u001b[0;32m   2965\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2966\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2967\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m my_missing)\n\u001b[0;32m   2968\u001b[0m     )\n\u001b[1;32m-> 2970\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, feature_names))\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['col_0', 'col_1', 'col_2', 'col_3', 'col_4', 'url_length', 'num_dots', 'num_hyphens', 'has_at', 'has_https', 'has_ip', 'count_suspicious_words'] ['url_length', 'num_dots', 'num_hyphens', 'has_at', 'has_https', 'has_ip', 'count_suspicious_words']\nexpected col_4, col_2, col_0, col_3, col_1 in input data"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load the saved Random Forest model\n",
    "xg_model = joblib.load(\"../model/XGboost_model_new.pkl\")\n",
    "\n",
    "# 2. Define a function to extract features from a new link\n",
    "def extract_features(url):\n",
    "    features = {}\n",
    "    features['URL'] = url  # <<< Add this line to fix the missing column\n",
    "    features['url_length'] = len(url)\n",
    "    features['num_dots'] = url.count('.')\n",
    "    features['num_hyphens'] = url.count('-')\n",
    "    features['has_at'] = int('@' in url)\n",
    "    features['has_https'] = int('https' in url.lower())\n",
    "    features['has_ip'] = int(any(char.isdigit() for char in url.split('/')[2])) if '://' in url else 0\n",
    "    features['count_suspicious_words'] = sum(word in url.lower() for word in ['login', 'secure', 'account', 'update', 'free', 'verify'])\n",
    "    return features\n",
    "\n",
    "# 3. Ask the user to input a new web address (URL)\n",
    "new_url = input(\"Enter the web address (URL) to check: \")\n",
    "\n",
    "# 4. Extract features from the entered URL\n",
    "url_features = extract_features(new_url)\n",
    "\n",
    "# 5. Convert the features into a DataFrame\n",
    "input_df = pd.DataFrame([url_features])\n",
    "\n",
    "# 6. Drop 'URL' column before prediction (since model expects features only)\n",
    "input_df = input_df.drop(columns=['URL'])\n",
    "\n",
    "# 7. Make a prediction\n",
    "prediction = xg_model.predict(input_df)[0]\n",
    "\n",
    "# 8. Output the result\n",
    "if prediction == 1:\n",
    "    print(\"⚠️ The URL is predicted to be **Phishing**.\")\n",
    "else:\n",
    "    print(\"✅ The URL is predicted to be **Legitimate**.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29787b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
